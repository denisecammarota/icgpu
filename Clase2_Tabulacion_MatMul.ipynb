{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Clase2_Tabulacion_MatMul.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/denisecammarota/icgpu/blob/main/Clase2_Tabulacion_MatMul.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6HXDOSw3hc-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b6487f12-4571-4d7a-f617-8ca38aec45ca"
      },
      "source": [
        "%%html\n",
        "<marquee style='width: 100%; color: blue;'><b>ICNPG2021 en Google Colaboratory-Instituto Balseiro-Clase 1 </b></marquee>\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<marquee style='width: 100%; color: blue;'><b>ICNPG2021 en Google Colaboratory-Instituto Balseiro-Clase 1 </b></marquee>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EH1rrvSR7z7t"
      },
      "source": [
        "# Preparativos para programar CUDA C/C++ en google colabs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8w8rRnK_fDB"
      },
      "source": [
        "Hola!, Bueno, aqui va un ejemplito de como correr codigo CUDA C/C++ en colabs\n",
        "[[1]](https://https://www.wikihow.com/Run-CUDA-C-or-C%2B%2B-on-Jupyter-(Google-Colab).\n",
        "\n",
        "No se olviden de Runtime-> Change Runtime Type -> GPU. Para que funque a cada linea la tienen que ejecutar con un Shift-Enter o Ctrl-Enter o el botoncito de play."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snj3bwGx_z-c"
      },
      "source": [
        "miremos que version de nvcc tenemos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GzIRSGebudXT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c7be3db-8a2b-4fc5-a86c-a101bd522aec"
      },
      "source": [
        "!nvcc --version"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2020 NVIDIA Corporation\n",
            "Built on Wed_Jul_22_19:09:09_PDT_2020\n",
            "Cuda compilation tools, release 11.0, V11.0.221\n",
            "Build cuda_11.0_bu.TC445_37.28845127_0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBqFrcSgAAYD"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjdc7qaxACgq"
      },
      "source": [
        "A ver que placa nos toco..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAOT_KANAFS6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac4fba3a-d2ec-43c9-f258-68b93e770e6d"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Apr 15 12:52:49 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.67       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P8    27W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zI2A2Sz0ARXc"
      },
      "source": [
        "lindas GPUs!!. Ahora, para poder correr Cuda C/C++ instalamos un plugin"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qustrOFnAZV8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8eb6af6-7f60-4628-d3df-be7ad6134add"
      },
      "source": [
        "!pip install git+git://github.com/andreinechaev/nvcc4jupyter.git\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+git://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning git://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-si2ow4d2\n",
            "  Running command git clone -q git://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-si2ow4d2\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-cp37-none-any.whl size=4307 sha256=505e0acb0646a16a474a281f3e63cb87d4a1ccc80a4894f1cc5174c218716f60\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ynit1yxe/wheels/10/c2/05/ca241da37bff77d60d31a9174f988109c61ba989e4d4650516\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FT5VL6VAh0U"
      },
      "source": [
        "y luego:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKpaprRBvkc3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f24ffd9-dd8f-49c1-d737-ef3d5d4a216b"
      },
      "source": [
        "%load_ext nvcc_plugin\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKtj2kNVLTcg"
      },
      "source": [
        "Listo!, con eso ya podemos correr codigo CUDA C/C++ en el notebook Jupyter."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bO4n1xfLK9oO"
      },
      "source": [
        "Para terminar, es conveniente montar nuestro google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNc_gJpPLCiT"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbvLlxFh7pZz"
      },
      "source": [
        "# Tabulación de un array en CPU y en GPU\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qZlO__byRoS"
      },
      "source": [
        "Completar y corregir el código siguiente para tabular un array en host y en device de cualquier tamaño. chequer la correctitud."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hvU9q4z-n0p"
      },
      "source": [
        "%%cu\n",
        "// solucion en la cpu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <assert.h>\n",
        "#include <ctime>\n",
        "#include \"/content/drive/MyDrive/Classroom/Introducción al Cálculo Numérico en Procesadores Gráficos Materia Optativa/Codigos_de_las_Clases/common/gpu_timer.h\"\n",
        "#include \"/content/drive/MyDrive/Classroom/Introducción al Cálculo Numérico en Procesadores Gráficos Materia Optativa/Codigos_de_las_Clases/common/cpu_timer.h\"\n",
        "\n",
        "#define SIZE\t1024\n",
        "#define NVECES\t1\n",
        "\n",
        "__device__ __host__ \n",
        "float MiFuncion(int i){\n",
        "    return sin(2*M_PI*i/10.0);    \n",
        "}\n",
        "\n",
        "__global__ void Tabular(float *d_c, int n)\n",
        "{\n",
        "        // indice de thread mapeado a indice de array \n",
        "        int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "        //COMPLETAR PARA QUE c[i]=MiFuncion(i)\n",
        "        //ASEGURARSE DE QUE TODO EL ARRAY ESTE TABULADO CON LA GRILLA LANZADA\n",
        "        //Y DE QUE NO SE ACCEDAN POSICIONES ILEGALES\n",
        "}\n",
        "\n",
        "int main(int argc, char **argv)\n",
        "{\n",
        "        int N;\n",
        "\n",
        "        if(argc==2) N=atoi(argv[1]);\n",
        "        else N=SIZE;\n",
        "\n",
        "        // punteros a memoria de host\n",
        "        float *c;\n",
        "\n",
        "        // alocacion memoria de host\n",
        "        c = (float *)malloc(N*sizeof(float));\n",
        "\n",
        "        /////////////////////// TABULACION EN CPU \n",
        "        // timer para gpu...\n",
        "        cpu_timer RelojCPU;\n",
        "        RelojCPU.tic();\n",
        "\n",
        "        // suma paralela en el device\n",
        "        for(int i=0;i<NVECES;i++){\n",
        "            for(int n=0;n<N;n++){\n",
        "              c[n]=MiFuncion(n);                \n",
        "            }\n",
        "        }\n",
        "\n",
        "        // verificacion del resultado\n",
        "        for( int i = 0; i < N; ++i){\n",
        "                if(i<10) printf(\"c[%d] = %f\\n\", i, c[i]);\n",
        "        }\n",
        "\n",
        "        // milisegundos transcurridos\n",
        "        printf(\"Tabular en CPU, N= %d t= %lf ms\\n\", N, RelojCPU.tac());    \n",
        "\n",
        "        /////////////////////// TABULACION EN GPU \n",
        "\n",
        "        // punteros a memoria de device\n",
        "        float *d_c;\n",
        "\n",
        "        // alocacion memoria de device\n",
        "        // COMPLETAR\n",
        "\n",
        "        // grilla de threads suficientemente grande...\n",
        "        // COMPLETAR LA CONFIGURACION DE LA GRILLA USANDO dim3 nThreads, nBlocks\n",
        "        // PARA QUE SE PUEDA TABULAR UN ARRAY DE CUALQUIER TAMANIO\n",
        "        dim3 nThreads(256); // CORREGIR\n",
        "        dim3 nBlocks(1); // CORREGIR\n",
        "\n",
        "        // suma paralela en el device: WARMING UP\n",
        "        Tabular<<< nBlocks, nThreads >>>(d_c, N);\n",
        "\n",
        "        // timer para gpu...\n",
        "        gpu_timer RelojGPU;\n",
        "        RelojGPU.tic();\n",
        "\n",
        "        // suma paralela en el device\n",
        "        for(int i=0;i<NVECES;i++)\n",
        "        Tabular<<< nBlocks, nThreads >>>(d_c, N);\n",
        "\n",
        "        // milisegundos transcurridos\n",
        "        printf(\"GPU: Tabular<<< %d, %d >>>, N= %d, t= %lf ms\\n\", nBlocks.x, nThreads.x, N, RelojGPU.tac());    \n",
        "\n",
        "        // copia (solo del resultado) del device a host\n",
        "        // COMPLETAR PARA TRAER LOS DATOS DE LA GPU, PONERLOS EN c[]\n",
        "        // .....\n",
        "\n",
        "        // verificacion del resultado\n",
        "        for( int i = 0; i < N; ++i){\n",
        "                if(i<10) printf(\"c[%d] = %f\\n\", i, c[i]);\n",
        "        }\n",
        "\n",
        "        // liberacion memoria de host\n",
        "        free(c);\n",
        "\n",
        "        // liberacion memoria de device\n",
        "        cudaFree(d_c);\n",
        "\n",
        "        return 0;\n",
        "}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELnPPd4s5i2b"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lw82ERMI7uiY"
      },
      "source": [
        "# ¿Que placa soy?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2R5aXvu71Ws"
      },
      "source": [
        "%%cu\n",
        "#include <stdio.h>\n",
        "\n",
        "int main(int argc, char **argv)\n",
        "{\n",
        "\tcudaDeviceProp deviceProp;\n",
        "\n",
        "\tint deviceCount = 0;\n",
        "    \tcudaError_t error_id = cudaGetDeviceCount(&deviceCount);\n",
        "\n",
        "\n",
        "\tprintf(\"En este nodo hay %d placas\\n\\n\",deviceCount);\n",
        "\tfor(int dev=0;dev<deviceCount;dev++){\n",
        "\t    \tcudaSetDevice(dev);\n",
        "    \t\tcudaGetDeviceProperties(&deviceProp, dev);\n",
        "    \t\tprintf(\"Hola!, yo soy [Device %d: \\\"%s\\\"], tu acelerador grafico personal\\n\", dev, deviceProp.name);\n",
        "\t}\n",
        "\n",
        "\tint dev; cudaGetDevice(&dev);\n",
        "\tprintf(\"\\nle asigno la device %d, que esta desocupada\\n\", dev);\n",
        "\n",
        "\treturn 0;\n",
        "}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3nbamuGAary"
      },
      "source": [
        "# Multiplicacion de Matrices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgoQQjF-EGjm"
      },
      "source": [
        "Completar para comparar la multiplicacion de matrices en paralelo (simple) y serial\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmtW2keuAf4I"
      },
      "source": [
        "%%cu\n",
        "#include<stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include \"/content/drive/MyDrive/Classroom/Introducción al Cálculo Numérico en Procesadores Gráficos Materia Optativa/Codigos_de_las_Clases/common/gpu_timer.h\"\n",
        "#include \"/content/drive/MyDrive/Classroom/Introducción al Cálculo Numérico en Procesadores Gráficos Materia Optativa/Codigos_de_las_Clases/common/cpu_timer.h\"\n",
        "\n",
        "// Matrices are stored in row-major order:\n",
        "// M(row, col) = *(M.elements + row * M.width + col)\n",
        "typedef struct {\n",
        "    int width;\n",
        "    int height;\n",
        "    float* elements;\n",
        "} Matrix;\n",
        "\n",
        "// Thread block size\n",
        "#define BLOCK_SIZE 16\n",
        "\n",
        "// Forward declaration of the matrix multiplication kernel\n",
        "__global__ void MatMulKernel(const Matrix, const Matrix, Matrix);\n",
        "\n",
        "// Matrix multiplication - Host code\n",
        "// Matrix dimensions are assumed to be multiples of BLOCK_SIZE\n",
        "void MatMul(const Matrix A, const Matrix B, Matrix C)\n",
        "{\n",
        "    // Load A and B to device memory\n",
        "    Matrix d_A;\n",
        "    d_A.width = A.width; d_A.height = A.height;\n",
        "    size_t size = A.width * A.height * sizeof(float);\n",
        "    cudaMalloc(&d_A.elements, size);\n",
        "    cudaMemcpy(d_A.elements, A.elements, size,\n",
        "               cudaMemcpyHostToDevice);\n",
        "    Matrix d_B;\n",
        "    d_B.width = B.width; d_B.height = B.height;\n",
        "    size = B.width * B.height * sizeof(float);\n",
        "    cudaMalloc(&d_B.elements, size);\n",
        "    cudaMemcpy(d_B.elements, B.elements, size,\n",
        "               cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Allocate C in device memory\n",
        "    Matrix d_C;\n",
        "    d_C.width = C.width; d_C.height = C.height;\n",
        "    size = C.width * C.height * sizeof(float);\n",
        "    cudaMalloc(&d_C.elements, size);\n",
        "\n",
        "    // Invoke kernel\n",
        "    dim3 dimBlock(BLOCK_SIZE, BLOCK_SIZE);\n",
        "    dim3 dimGrid(B.width / dimBlock.x, A.height / dimBlock.y);\n",
        "    MatMulKernel<<<dimGrid, dimBlock>>>(d_A, d_B, d_C);\n",
        "\n",
        "    // Read C from device memory\n",
        "    cudaMemcpy(C.elements, d_C.elements, size,\n",
        "               cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Free device memory\n",
        "    cudaFree(d_A.elements);\n",
        "    cudaFree(d_B.elements);\n",
        "    cudaFree(d_C.elements);\n",
        "}\n",
        "\n",
        "// Matrix multiplication kernel called by MatMul()\n",
        "__global__ void MatMulKernel(Matrix A, Matrix B, Matrix C)\n",
        "{\n",
        "    // Each thread computes one element of C\n",
        "    // by accumulating results into Cvalue\n",
        "    float Cvalue = 0;\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    for (int e = 0; e < A.width; ++e)\n",
        "        Cvalue += A.elements[row * A.width + e]\n",
        "                * B.elements[e * B.width + col];\n",
        "    C.elements[row * C.width + col] = Cvalue;\n",
        "}\n",
        "\n",
        "\n",
        "// Matrix multiplication in cpu\n",
        "void MatMulcpu(Matrix A, Matrix B, Matrix C)\n",
        "{\n",
        "//TODO: completar para que C=A*B en la cpu\n",
        "}\n",
        "\n",
        "#define DIM\t1024\n",
        "#define  IDX2C(i,j,ld) (((j)*(ld))+( i ))\n",
        "\n",
        "int main(int argc, char **argv)\n",
        "{\n",
        "\t//TODO: completar\n",
        "\t// (1) alocar e inicializar A y B en host\n",
        "\t// (2) chequear y cronometrar MatMul\n",
        "\t// (3) chequear y cronometrar MatMulcpu\n",
        "\t// (4) Comparar CPU vs GPU para distintos tamaños de matriz\n",
        "\n",
        "        return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}